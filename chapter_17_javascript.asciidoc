[[chapter_17_javascript]]
== A Gentle Excursion Into JavaScript

.A Note for Early Release Readers
****
With Early Release ebooks, you get books in their earliest form—the author's raw and unedited content as they write—so you can take advantage of these technologies long before the official release of these titles.

This will be the 17th chapter of the final book. The GitHub repo is available at https://github.com/hjwp/book-example.

If you have comments about how we might improve the content and/or examples in this book, or if you notice missing material within this chapter, please reach out to the author at obeythetestinggoat@gmail.com.
****

[quote, Geoffrey Willans, English author and journalist]
______________________________________________________________
You can never understand one language until you understand at least two.
______________________________________________________________


.Warning, Fresh rewrite
*******************************************************************************
This chapter is a fresh rewrite for the third edition.

I've switched from QUnit to Jasmine for the JavaScript testing,
and updated all the listings to use modern ES6 JavaScript.

It's still in early drafts, so I'd love your feedback!
obeythetestinggoat@gmail.com

*******************************************************************************

Our new validation logic is good,
but wouldn't it be nice if the duplicate item error messages disappeared
once the user started fixing the problem?
Just like our nice HTML5 validation errors do?

Try it--spin up the site with `./src/manage.py runserver`,
start a list, and if you try to submit an empty item,
you get the "Please fill out this field" pop-up,
and it disappears as soon as you enter some text.
By contrast, enter an item twice,
you get the "You've already got this in your list" message in red,
but even if you edit your submission to something valid,
the error stays there until you submit the form (see <<duplicate_item_error>>).

[[duplicate_item_error]]
.But I've fixed it!
image::images/duplicate_item_error.png["A screenshot of the 'Please fill out this field' error in red, still shown despite the fact that the input value has been modified to be different from the existing item in the list"]

To get that error to disappear dynamically, we'd need a teeny-tiny bit of JavaScript.

Python is a delightful language to program in.
JavaScript wasn't always that.
But many of the rough edges have been smoothed off,
and I think it's fair to say that JavaScript is actually quite nice now.
And in the world of web development, using JavaScript is unavoidable.
So let's dip our toes in, and see if we can't have a bit of fun.

// RITA: Consider dropping mention of JavaScript: The Good Parts and just referencing your more recent recommendations. If you've read Eloquent JavaScript, consider dropping "I've heard good things" to make your recommendation sound more confident. I suppose you could still mention JavaScript: The Good Parts after that.
NOTE: I'm going to assume you know the basics of JavaScript syntax.
  If not, I used to recommend https://amzn.to/3UXVUKd[JavaScript: The Good Parts],
  which was the best guide, once upon a time.
  Nowadays many of the "bad parts" it warns against have actually been fixed,
  so it's a little out of date.
  I'd say it's still a good guide, but if you find it too anachronistic,
  I've heard good things about
  https://eloquentjavascript.net[Eloquent JavaScript].
  ((("JavaScript testing", "additional resources")))

// CSANAD: maybe we could also mention MDN
// https://developer.mozilla.org/en-US/docs/Web/JavaScript#for_complete_beginners




=== Starting with an FT

((("JavaScript testing", "functional test")))
((("functional tests (FTs)", "JavaScript", id="FTjava16")))

Let's add a new functional test to the `ItemValidationTest` class,
that asserts that our error message disappears when we start typing:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l001)
====
[source,python]
----
def test_error_messages_are_cleared_on_input(self):
    # Edith starts a list and causes a validation error:
    self.browser.get(self.live_server_url)
    self.get_item_input_box().send_keys("Banter too thick")
    self.get_item_input_box().send_keys(Keys.ENTER)
    self.wait_for_row_in_list_table("1: Banter too thick")
    self.get_item_input_box().send_keys("Banter too thick")
    self.get_item_input_box().send_keys(Keys.ENTER)
    self.wait_for(  # <1>
        lambda: self.assertTrue(  # <1>
            self.browser.find_element(
                By.CSS_SELECTOR, ".invalid-feedback"
            ).is_displayed()  # <2>
        )
    )

    # She starts typing in the input box to clear the error
    self.get_item_input_box().send_keys("a")

    # She is pleased to see that the error message disappears
    self.wait_for(
        lambda: self.assertFalse(
            self.browser.find_element(
                By.CSS_SELECTOR, ".invalid-feedback"
            ).is_displayed()  # <2>
        )
    )
----
====

<1> We use another of our `wait_for` invocations, this time with `assertTrue`.

<2> `is_displayed()` tells you whether an element is visible or not.
    We can't just rely on checking whether the element is _present_ in the DOM,
    because we're now going to mark elements as hidden,
    rather than removing them from the DOM altogether.


The functional test fails appropriately:



[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*]

FAIL: test_error_messages_are_cleared_on_input (functional_tests.test_list_item
_validation.ItemValidationTest.test_error_messages_are_cleared_on_input)
[...]
  File "...goat-book/src/functional_tests/test_list_item_validation.py", line
89, in <lambda>
    lambda: self.assertFalse(
            ~~~~~~~~~~~~~~~~^
        self.browser.find_element(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
            By.CSS_SELECTOR, ".invalid-feedback"
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        ).is_displayed()
        ^^^^^^^^^^^^^^^^
    )
    ^
AssertionError: True is not false
----

But, before we move on:  three strikes and refactor!
We've got several places where we find the error element using CSS.
Let's move the logic to a helper function:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l002)
====
[source,python]
----
class ItemValidationTest(FunctionalTest):
    def get_error_element(self):
        return self.browser.find_element(By.CSS_SELECTOR, ".invalid-feedback")

    [...]
----
====

And we then make three replacements in 'test_list_item_validation', like this:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l003)
====
[source,python]
----
    self.wait_for(
        lambda: self.assertEqual(
            self.get_error_element().text,
            "You've already got this in your list",
        )
    )
[...]
    self.wait_for(
        lambda: self.assertTrue(self.get_error_element().is_displayed()),
    )
[...]
    self.wait_for(
        lambda: self.assertFalse(self.get_error_element().is_displayed()),
    )
----
====

We still have our expected failure:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python src/manage.py test functional_tests.test_list_item_validation*]
[...]
    lambda: self.assertFalse(self.get_error_element().is_displayed()),
            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: True is not false
----


TIP: I like to keep helper methods in the FT class that's using them,
    and only promote them to the base class when they're actually needed elsewhere.
    It stops the base class from getting too cluttered. YAGNI.

[[js-spike]]
=== A Quick "Spike"

((("spike")))
((("exploratory coding", see="also spiking and de-spiking")))
((("spiking and de-spiking", "defined")))
((("prototyping", see="spiking and de-spiking")))
This will be our first bit of JavaScript.
We're also interacting with the Bootstrap CSS framework,
which we maybe don't know very well.

In <<chapter_15_simple_form>> we saw that you
can use a unit test as a way of exploring a new API or tool.
Sometimes though, you just want to hack something together
without any tests at all, just to see if it works,
to learn it or get a feel for it.

That's absolutely fine.
When learning a new tool or exploring a new possible solution,
it's often appropriate to leave the rigorous TDD process to one side,
and build a little prototype without tests, or perhaps with very few tests.
The goat doesn't mind looking the other way for a bit.

This kind of prototyping activity is often called a "spike",
for http://stackoverflow.com/questions/249969/why-are-tdd-spikes-called-spikes[
reasons that aren't entirely clear],
but it's a nice memorable name.footnote:[
This chapter shows a very small spike.
We'll come back and look at the spiking process again,
with a weightier Python/Django example,
in <<chapter_19_spiking_custom_auth>> .]

Before we start, let's commit our FT.  When embarking on a slate,
you want to be able to get back to a clean slate.

[subs="specialcharacters,quotes"]
----
$ *git diff*  # new method in src/tests/functional_tests/test_list_item_validation.py
$ *git commit -am"FT that validation errors disapper on type"
----


TIP: Always do a commit before embarking on a Spike.


==== A Simple Inline Script

I hacked around for a bit,
and here's more or less the first thing I came up with.
I'm adding the javascript inline, in a `<script>` tag
at the bottom of our _base.html_ template:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l004)
====
[source,html]
----
    [...]
    </div>

    <script>
      const textInput = document.querySelector("#id_text");  //<1>
      textInput.oninput = () => {  //<2><3>
        const errorMsg = document.querySelector(".invalid-feedback");
        errorMsg.style.display = "none";  //<4>
      }
    </script>

  </body>
</html>
----
====

<1> `document.querySelector` is a way of finding an element in the DOM,
    using CSS selector syntax, very much like the Selenium
    `find_element(By.CSS_SELECTOR)` method from our FTs.
    Grizzled readers may remember having to use jQuery's `$` function for this.

<2> `oninput` is how you attach an event listener "callback" function,
    which will be called whenever the user inputs something into the text box.

<3> Arrow functions `() => {...}` are the new way of writing anonymous functions
    in JavaScript, a bit like Python's `lambda` syntax.
    I think they're cute!
    Arguments go in the round brackets,
    the function body goes in the curly braces.
    So this is a function that takes no arguments,
    or I should say, ignores any arguments you try to give it.
    What does it do?

<4> It finds the error message element,
    and then hides it by setting its `style.display` to "none".

That's actually good enough to get our FT passing:

[subs="specialcharacters,quotes"]
----
$ *python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*
Found 1 test(s).
[...]
.
 ---------------------------------------------------------------------
Ran 1 test in 3.284s

OK
----


TIP: It's good practice to put your script loads at the end of your body HTML,
    as it means the user doesn't have to wait for all your JavaScript to load
    before they can see something on the page.
    It also helps to make sure most of the DOM has loaded before any scripts run.
    See also the <<columbo-onload>> section, later in this chapter.


==== Using the Browser Devtools

The test might be happy, but our solution is a little unsatisfactory.
If you actually try it in your browser,
you'll see that although the error message is gone,
the input is still red and invalid-looking, see <<input-still-red>>.

[[input-still-red]]
.The error message is gone but the input box is still red
image::images/error-gone-but-input-still-red.png["Screenshot of our page where the error div is gone but the input is still red."]

You're probably imagining that this has something to do with Bootstrap.
We might have been able to hide the error message,
but we also need to tell bootstrap that this input no longer has invalid contents.

This is where I'd normally open up devtools.
If level 1 of hacking is spiking code directly into an inline `<script>` tag,
level 2 is hacking things directly in the browser,
where it's not even saved to a file!

[[editing-html-in-devtools]]
.Editing the HTML in the Browser Devtools
image::images/editing-html-via-devtools.png["Screenshot of the browser devtools with us editing the classes for the input element"]

In <<editing-html-in-devtools>> you can see me directly editing the HTML of the page,
and finding out that removing the `is-invalid` class from the input element
seems to do the trick.
It not only removes the error message,
but also the red border around the input box.

We have a reasonable solution now, let's write it down:

[role="scratchpad"]
*****
* Remove `is-invalid` bootstrap css class to hide error message & red border
*****

Time to de-spike!


.Do We Really Need to Write Unit Tests for This?
*******************************************************************************

Do we really need to write unit tests for this?
By this point in the book, you probably know I'm going to say "yes",
but let's talk about it anyway.

Our FT definitely covers the functionality that our JavaScript is delivering,
and we could extend it if we wanted to,
to check on the colour of the input box,
or to look at the input element's CSS classes.

And if I was really sure that this was the _only_ bit of JavaScript
we were ever going to write,
I probably would be tempted to leave it at that.

But I want to press on for two reasons.
Firstly, because any book on web development has to talk about JavaScript,
and in a TDD book, I have to show a bit of TDD in JavaScript.

More importantly though, as always we have the boiled frog problem.
We might not have enough JavaScript _yet_ to justify a full test suite,
but what about when we come along later and add a tiny bit more?
And a tiny bit more again?

It's always a judgement call, and on the one hand YAGNI,
but on the other hand, I think it's best to put the scaffolding in place early,
so that going test-first is the easy choice later.

I can already think of several extra things I'd want to do in the frontend!
What about re-setting the input to being invalid if someone types in the
exact duplicate text again?

*******************************************************************************


=== Choosing a Basic JavaScript Test Runner


((("test running libraries")))
((("JavaScript testing", "test running libraries", id="JStestrunner16")))
((("pytest")))
Choosing your testing tools in the Python world is fairly straightforward.
The standard library `unittest` package is perfectly adequate,
and the Django test runner also makes a good default choice.
More and more though, people will choose http://pytest.org/[pytest]
for its `assert` based assertions, and its fixture management.
We don't need to get into the pros and cons now!
The point is that there's a "good enough" default,
and there's one main popular alternative.

The JavaScript world has more of a proliferation!
Mocha, Karma, Jester, Chai, Ava, and Tape are just a few of the options
I came across when researching the Third Edition.

I chose Jasmine, because it's still popular despite being around for nearly a decade,
and because it offers a "standalone" test runner that you can use
without needing to dive into the whole Node/NPM ecosystem.
((("Jasmine")))


=== An Overview of Jasmine

By now we're used to the way that tests with Python's `unittest` library works:

1. We have a tests file, separate from the code we're actually testing
2. We have a way of grouping blocks of code into "a test":
  it's a method, whose name starts with `test_`, on a class that inherits
  from `unittest.TestCase`
3. We have a way of making "assertions" in the test
  (the special `assert` methods, eg `self.assertEqual()`)
4. We have a way of grouping related tests together
  (putting them in the same class),
5. We can specify shared "setup" and "cleanup" code
  that runs before and after all the tests in a given group,
  the `setUp()` and `tearDown()` methods.
6. We have some additional helpers that set up our app in a way that simulates
  what happens "in real life" -- whether that's Selenium and the `LiveServerTestCase`,
  or the Django Test Client.  This is sometimes called the "test harness".

There are going to be fairly straightforward equivalents for the first 5 of these concepts in Jasmine:

1. A tests file (_Spec.js_)
2. Tests go into an anonymous function inside an `it()` block.
3. Assertions use a special function called `expect()`,
  with a syntax based on method chaining for asserting equality.
4. Blocks of related tests go into a function in a `describe()` block.
5. `setUp()` and `tearDown()` are called `beforeEach()` and `afterEach()` respectively.

There are some differences for sure, but you'll see over the course of the chapter
that they're fundamentally the same.

What _is_ substantially different is the "test harness" part,
the way that Jasmine creates an environment for us to work against.

Because we're using the browser runner,
what we're actually going to do is define an HTML file
(_SpecRunner.html_)
and the "engine" for running our code is going to be an actual browser
(with JavaScript running inside it).

That html will be the "entrypoint" for our tests, so it will be in charge
of "importing" our framework, our tests file, and the code under test.
It's essentially a parallel, standalone web page, that's not actually part of our app,
but that _does_ import the same JavaScript source code as our app uses.


=== Setting Up Our JavaScript Test Environment

// TODO: go all in and use jasmine-browser-runner instead,
// it will let me use ES6 modules.

Let's download Jasmine now:

[role="small-code"]
[subs="specialcharacters,quotes"]
----
$ *wget -O jasmine.zip \
  https://github.com/jasmine/jasmine/releases/download/v4.6.1/jasmine-standalone-4.6.1.zip*
$ *unzip jasmine.zip -d src/lists/static/tests*
$ *rm jasmine.zip*
# if you're on Windows you may not have wget or unzip,
# but i'm sure you can manage to manually download and unzip the jasmine release

# move the example tests "Spec" file to a more central location
$ *mv src/lists/static/tests/spec/PlayerSpec.js src/lists/static/tests/Spec.js*

# delete all the other stuff we don't need
$ *rm -rf src/lists/static/tests/src*
$ *rm -rf src/lists/static/tests/spec*
----
//005-1

That leaves us with a directory structure like this:

[subs="specialcharacters,quotes"]
----
$ *tree src/lists/static/tests*
src/lists/static/tests
├── MIT.LICENSE
├── Spec.js
├── SpecRunner.html
└── lib
    └── jasmine-4.6.1
        ├── boot0.js
        ├── boot1.js
        ├── jasmine-html.js
        ├── jasmine.css
        ├── jasmine.js
        └── jasmine_favicon.png

3 directories, 9 files
----

_SpecRunner.html_ is the file that ties the proverbial room together,
so we need to go edit it to make sure it's pointing at the right places,
to take into account the things we've moved around:


[role="sourcecode"]
.src/lists/static/tests/SpecRunner.html (ch16l006)
[source,diff]
----
@@ -14,12 +14,10 @@
   <script src="lib/jasmine-4.6.1/boot1.js"></script>

   <!-- include source files here... -->
-  <script src="src/Player.js"></script>
-  <script src="src/Song.js"></script>
+  <script src="../lists.js"></script>

   <!-- include spec files here... -->
-  <script src="spec/SpecHelper.js"></script>
-  <script src="spec/PlayerSpec.js"></script>
+  <script src="Spec.js"></script>

 </head>
----

We change the "source files" to point at a (for-now imaginary)
_lists.js_ file that we'll put into the _static_ folder,
and we change the "spec files" to point at the single _Spec.js_ file,
in the _static/tests_ folder.

=== Our First Smoke Test: Describe, It, Expect

Now let's open up that _Spec.js_ file,
and strip it down to a single minimal smoke test:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l007)
====
[source,javascript]
----
describe("Superlists tests", () => {  //<1>

  it("smoke test", () => {  //<2>
    expect(1 + 1).toEqual(2);  //<3>
  });

});
----
====


<1> The `describe` block is a way of grouping tests together,
    a bit like we use classes in our Python tests.
    It starts with a string name, and then an arrow function for its body.

<2> The `it` block is a single test, a bit like a method in a Python test class.
    Similarly to the `describe` block,
    we have a name and then a function to contain the test code.

<3> Now we have our assertion.
    This is a little different from assertions in unittest;
    it's using what's sometimes called "expect" style,
    often also seen in the Ruby world.
    We wrap our "actual" value in the `expect()` function,
    and then our assertions are methods on the resulting expect object,
    where `.toEqual` is the equivalent of `assertEqual` in Python.


==== Running The Tests Via the Browser

Let's see how that looks.
Open up _SpecRunner.html` in your browser;
you can do this from the command-line with

[role="skipme"]
[subs="specialcharacters,quotes"]
----
$ *firefox src/lists/static/tests/SpecRunner.html*
# or, on a mac:
$ *open src/lists/static/tests/SpecRunner.html*
----

Or you can navigate to it using the address bar,
using the `file://` protocol, something like this:
_file&*58;//home/your-username/path/to/superlists/src/lists/static/tests/SpecRunner.html_

Either way you get there, you should see something like <<jasmine-specrunner-green>>.

[[jasmine-specrunner-green]]
.The Jasmine Spec runner in action
image::images/jasmine-in-browser-green.png["Jasmine browser-based spec runner showing one passing test."]


Let's try adding a deliberate failure to see what that looks like:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l008)
====
[source,javascript]
----
  it("smoke test", () => {
    expect(1 + 1).toEqual(3);
  });
----
====

Now if we refresh our browser, we'll see red (<<jasmine-specrunner-red>>):

[[jasmine-specrunner-red]]
.Our Jasmine tests are now red
image::images/jasmine-in-browser-red.png["Jasmine browser-based spec runner showing one failing test, with lots of red."]


.Is the Jasmine Standalone Browser Test Runner Unconventional?
*******************************************************************************

Is the Jasmine standalone browser test runner unconventional?
I think it probably is, to be honest.
Although the JavaScript world moves so fast,
I could be wrong by the time you read this.

What I do know is that, along with moving very fast,
JavaScript things can very quickly become very complicated.
A lot of people are working with frameworks these days (React is the main one),
and along with that comes TypeScript, transpilers, to say nothing of Node.js,
`npm`, the `node_modules` folder, and a very steep learning curve.

In this chapter my aim is to stick with the basics.
The standalone / browser-based test runner lets us write tests without
needing to install node or anything else,
and it lets us tests interactions with the DOM.

That's enough to give us a basic environment in which to do TDD in JavaScript.

If you decide to go further in the world of frontend,
you probably will eventually get into the complexity of frameworks
and TypeScript and transpilers,
but the basics we work with here will still be a good foundation.

We will actually take things a small step further in this book,
including dipping our toes into NPM and Node.js, in <<chapter_25_CI>>,
where we _will_ get CLI-based js tests working.
So, look out for that!
*******************************************************************************


((("", startref="JStestrunner16")))
((("", startref="qunit16")))


=== Testing with some DOM content

What do we _actually_ want to test?
We want some JavaScript that will hide the `.invalid-feedback` error div,
when the user starts typing into the input box.

In other words, our code is going to interact with the `input` element
on the page, and the `div.invalid-feedback`.

Let's see how to set up some copies of these elements in our JS test environment,
for our tests and our code to interact with.


[role="sourcecode dofirstch16l009"]
.src/lists/static/tests/Spec.js (ch16l010)
====
[source,javascript]
----
describe("Superlists tests", () => {
  let testDiv;  //<4>

  beforeEach(() => {  //<1>
    testDiv = document.createElement("div");  //<2>
    testDiv.innerHTML = `  //<3>
      <form>
        <input
          id="id_text"
          name="text"
          class="form-control form-control-lg is-invalid"
          placeholder="Enter a to-do item"
          value="Value as submitted"
          aria-describedby="id_text_feedback"
          required
        />
        <div id="id_text_feedback" class="invalid-feedback">An error message</div>
      </form>
    `;
    document.body.appendChild(testDiv);
  });

  afterEach(() => {  //<1>
    testDiv.remove();
  });
----
====

<1> The `beforeEach` and `afterEach` functions are Jasmine's equivalent of `setUp` and `tearDown`.

<2> The `document` global is a builtin browser variable
  that represents the current HTML page.
  So in our case, it's a reference to the _SpecRunner.html_ page.

<3> We create a new div element, and populate it with some HTML that matches
  the elements we care about from our Django template.
  Notice the use of backticks (+`+) to allow us to write multi-line strings.
  Depending on your text editor, it may even nicely syntax-highlight the HTML for you.

<4> A little quirk of JavaScript here,
  because we want the same `testDiv` variable to be available inside both the
  `beforeEach` and `afterEach` functions, we declare the variable with this `let`
  in the containing scope outside of both of them.

In theory, we could have just added the HTML to the `SpecRunner.html` file,
but by using `beforeEach` and `afterEach`,
I'm making sure that each test gets a completely fresh copy of the html elements involved,
so that one test can't affect another.

TIP:  To ensure isolation between browser-based JavaScript tests,
      use `beforeEach()` and `afterEach()` to create and tidy up any DOM elements
      that your code needs to interact with.

Let's now have a play with our testing framework,
to see if we can find DOM elements and make assertions on whether they are visible.
We'll also try the same `style.display=none` hiding technique
that we originally used in our spiked code.


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l011)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);  //<1>
  });

  it("check we know how to hide things", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";  //<2>
    expect(errorMsg.checkVisibility()).toBe(false);  //<3>
  });
----
====

// CSANAD: I personally like phrasing test messages in singular 3rd person
// because then it reads more natural:
// "it checks whether foo does bar" so I suggest
// "sense-checks our html fixture".
// Also, I would refine the second test's message, maybe:
// "checks if we know how to hide things" or
// "checks if display set to none hides the element"
//
// Same chain of thought: I also prefer the `describe()` description to
// flow into the it() -s:
// ```
// describe("Superlists", () => {
//   it("should foo when bar");
//   it("should not baz if qux")
// })
// ```
// reads as nice sentences in the test output:
// Superlists > should foo when bar
// Superlists > should not baz if qux

<1> We retrieve our error div with `querySelector` again,
    and then use another fairly new API in JavaScript-Land called `checkVisibility()`
    to check if it's displayed or hidden.footnote:[
Read up on `checkVisibility()` at https://developer.mozilla.org/en-US/docs/Web/API/Element/checkVisibility]

<2> We _manually_ hide the element in the test,
  by setting its `style.display` to "none".
  (Again, our objective here is to smoke-test,
  both our ability to hide things,
  and our ability to test that they are hidden.)

<3> And we check it worked, with `checkVisibility()` again.



Notice that I'm being really good about splitting things out into multiple tests,
with one assertion each.
Jasmine encourages that, for example, by deprecating the ability to pass
on-failure messages into individual `expect/toBe` expressions.

If you refresh the browser, you should see that all passes:

[[first-jasmine-output]]
.Expected results from Jasmine in the browser
====
[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * check we know how to hide things
  * sense-check our html fixture
----
====

(I'll show the Jasmine outputs as text, as in <<first-jasmine-output>>, from now on,
to avoid filling the chapter with screenshots.)



=== Building a JavaScript Unit Test for Our Desired Functionality


((("JavaScript testing", "unit test")))
((("unit tests", "JavaScript")))
Now that we're acquainted with our JavaScript testing tools,
we can start to write the real thing:


[role="sourcecode small-code"]
.src/lists/static/tests/Spec.js (ch16l012)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {  //<1>
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {  //<2>
    const textInput = document.querySelector("#id_text");  //<3>
    const errorMsg = document.querySelector(".invalid-feedback");

    textInput.dispatchEvent(new InputEvent("input"));  //<4>

    expect(errorMsg.checkVisibility()).toBe(false);  //<5>
  });
----
====

<1> Let's keep the first smoke test, it's not doing any harm.

<2> Let's change the second one, and give it a name that describes
  what we want to happen;
  our objective is that, when the user starts typing into the input box,
  we should hide the error message.
// CSANAD: just like above, I would phrase it in 3rd person singular:
// it("hides the error message element on input", or
// it("checks if the error message is hidden on input", or something like this.

<3> We retrieve the `<input>` element from the DOM,
  in a similar way to how we found the error message div.

<4> Here's how we simulate a user typing into the input box.

<5> And here's our real assertion: the error div should be hidden after
  the input box sees an input event.


That gives us our expected failure:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:38:40
<Jasmine>
----


Now let's try re-introducing the code we hacked together in our spike,
into _lists.js_:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l014)
====
[source,javascript]
----
const textInput = document.querySelector("#id_text");
textInput.oninput = () => {
  const errorMsg = document.querySelector(".invalid-feedback");
  errorMsg.style.display = "none";
};
----
====


That doesn't work!  We get an _unexpected error_:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 2 failures, randomized with seed 12345      finished in 0.005s
Error during loading: TypeError: textInput is null in
file:///...goat-book/src/lists/static/lists.js line 2
Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:38:40
<Jasmine>
----


If your Jasmine output shows `Script error` instead of `textInput is null`,
open up the dev tools console, and you'll see the actual error printed in there,
as in <<typeerror-in-devools>>.footnote:[
Some users have also reported that Google Chrome will show a different
error, to do with the browser preventing loading local files.
If you really can't use Firefox, you might be able to find some solutions here:
https://stackoverflow.com/questions/20748630/load-local-javascript-file-in-chrome-for-testing]

[[typeerror-in-devools]]
.textInput is null, one way or another
image::images/typeerror_in_devools.png["Screenshot of devtools console showing the textInput is null TypeError"]

`textInput is null` it says.   Let's see if we can figure out why.


=== Fixtures, Execution Order, and Global State: Key Challenges of JS Testing


((("JavaScript testing", "managing global state")))
((("global state")))
((("JavaScript testing", "key challenges of", id="JSTkey16")))
((("HTML fixtures")))
One of the difficulties with JavaScript in general, and testing in particular,
is in understanding the order of execution of our code (i.e., what happens when).
When does our code in _lists.js_ run, and when does each of our tests run?
And how does that interact with global state, that is, the DOM of our web page,
and the fixtures that we've already seen are supposed to be cleaned up after each test?


==== console.log for Debug Printing

((("print", "debugging with")))
((("debugging", "print-based")))
((("console.log")))
Let's add a couple of debug prints, or "console.logs":

[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l015)
====
[source,javascript]
----
console.log("Spec.js loading");

describe("Superlists tests", () => {
  let testDiv;

  beforeEach(() => {
    console.log("beforeEach");
    testDiv = document.createElement("div");

    [...]

  it("sense-check our html fixture", () => {
    console.log("in test 1");
    const errorMsg = document.querySelector(".invalid-feedback");
    [...]

  it("error message should be hidden on input", () => {
    console.log("in test 2");
    const textInput = document.querySelector("#id_text");
    [...]
----
====

And the same in our actual JS code:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l016)
====
[source,javascript]
----
console.log("lists.js loading");
const textInput = document.querySelector("#id_text");
textInput.oninput = () => {
  const errorMsg = document.querySelector(".invalid-feedback");
  errorMsg.style.display = "none";
};
----
====


Rerun the tests, opening up the browser debug console (Ctrl-Shift-I or Cmd-Alt-I)
and you should see something like <<jasmine-with-js-console>>.

[[jasmine-with-js-console]]
.Jasmine tests with console.log debug outputs
image::images/jasmine-console-logs.png["Jasmine tests with console.log debug outputs"]

What do we see?

* _lists.js_ loads first
* then we see the error saying `textInput is null`
* then we see our tests loading in Spec.js
* then we see a `beforeEach`, which is when our test fixture actually gets added to the DOM
* then we see the first test run.

This explains the problem: when _lists.js_ loads,
the input node doesn't exist yet.



=== Using an Initialize Function for More Control Over Execution Time

We need more control over the order of execution of our JavaScript.
Rather than just relying on the code in _lists.js_ running
whenever it is loaded by a `<script>` tag,
we can use a common pattern, which is to define an "initialize" function,
and call that when we want to in our tests (and later in real life):


[role="sourcecode"]
.src/lists/static/lists.js (ch16l017)
====
[source,javascript]
----
console.log("lists.js loading");
const initialize = () => {
  console.log("initialize called");
  const textInput = document.querySelector("#id_text");
  textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  };
};
----
====


And in our tests file, we call `initialize()` in our key test:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l018)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    console.log("in test 1");
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {
    console.log("in test 2");
    const textInput = document.querySelector("#id_text");
    const errorMsg = document.querySelector(".invalid-feedback");

    initialize();  //<1>
    textInput.dispatchEvent(new InputEvent("input"));

    expect(errorMsg.checkVisibility()).toBe(false);
  });
});
----
====

<1> Here.  We don't need to call it in our sense-check.


And that will actually get our tests passing!


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
----


And now the `console.log` outputs should be in a more sensible order:

[role="skipme"]
----
lists.js loading            lists.js:1:9
Spec.js loading             Spec.js:1:9
beforeEach                  Spec.js:7:13
in test 1                   Spec.js:31:13
beforeEach                  Spec.js:7:13
in test 2                   Spec.js:37:13
initialize called           lists.js:3:11
----


=== Deliberately Breaking Our Code to Force Ourselves To Write More Tests

I'm always nervous when I see green tests.
We've copy-pasted five lines of code from our spike with just one test.
That was a little too easy,
even if we did have to go through that little `initialize()` dance.

So let's change our `initialize()` function to deliberately break it.
What if we just immediately hide errors?

[role="sourcecode"]
.src/lists/static/lists.js (ch16l019)
====
[source,javascript]
----
const initialize = () => {
  // const textInput = document.querySelector("#id_text");
  // textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  // };
};
----
====


Oh dear, as I feared, the tests just pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
----


We need an extra test, to check that our `initialize()` function
isn't overzealous:



[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l020)
====
[source,javascript]
----
  it("error message should be hidden on input", () => {
    [...]
  });

  it("error message should not be hidden before input is fired", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    initialize();
    expect(errorMsg.checkVisibility()).toBe(true);  //<1>
  });
----
====
// CSANAD: suggestion for test message:
// `it("should not hide the error message before providing input",...`

<1> In this test we don't fire the input event with `dispatchEvent`,
  so we expect the error message to still be visible.


That gives us our expected failure:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should not be hidden before input is fired
Expected false to be true.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:48:40
<Jasmine>
----


Which justifies us to restore the `textInput.oninput()`:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l021)
====
[source,javascript]
----

const initialize = () => {
  const textInput = document.querySelector("#id_text");
  textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  };
};
----
====


=== Red, Green, Refactor: Removing Hardcoded Selectors

The `#id_text` and `.invalid-feedback` selectors are "magic constants" at the moment.
It would be better to pass them in to `initialize()`,
both in the tests and in _base.html_,
so that they're defined in the same file that actually has the HTML elements.

And while we're at it, our tests could do with a bit of refactoring too,
to remove some duplication.  We'll start with that,
by defining a few more variables in the top-level scope,
and populate them in the `beforeEach`:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l022)
====
[source,javascript]
----
describe("Superlists tests", () => {
  const inputId = "id_text";  //<1>
  const errorClass = "invalid-feedback";  //<1>
  const inputSelector = `#${inputId}`;  //<2>
  const errorSelector = `.${errorClass}`;  //<2>
  let testDiv;
  let textInput;  //<3>
  let errorMsg;  //<3>

  beforeEach(() => {
    console.log("beforeEach");
    testDiv = document.createElement("div");
    testDiv.innerHTML = `
      <form>
        <input
          id="${inputId}"  //<4>
          name="text"
          class="form-control form-control-lg is-invalid"
          placeholder="Enter a to-do item"
          value="Value as submitted"
          aria-describedby="id_text_feedback"
          required
        />
        <div id="id_text_feedback" class="${errorClass}">An error message</div>  //<4>
      </form>
    `;
    document.body.appendChild(testDiv);
    textInput = document.querySelector(inputSelector);  //<5>
    errorMsg = document.querySelector(errorSelector);  //<5>
  });
----
====

<1> Let's define some constants to represent the selectors for our input element
    and our error message div.

<2> We can use JavaScript's string interpolation (the equivalent of f-strings)
    to then define the css selectors for the same elements.

<3> We'll also set up some variables to hold the elements we're always referring
    to in our tests (these can't be constants, as we'll see shortly).

<4> We use a bit more interpolation to reuse the constants in our HTML template.
    A first bit of deduplication!

<5> Here's why `textInput` and `errorMsg` can't be constants:
    we're re-creating the DOM fixture in every `beforeEach`,
    so we need to re-fetch the elements each time.


Now we can apply some DRY to strip down our tests:



[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l023)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {
    initialize();
    textInput.dispatchEvent(new InputEvent("input"));

    expect(errorMsg.checkVisibility()).toBe(false);
  });

  it("error message should not be hidden before input is fired", () => {
    initialize();
    expect(errorMsg.checkVisibility()).toBe(true);
  });
----
====

You can definitely overdo DRY in test,
but I think this is working out very nicely.
Each test is between one and three lines long,
meaning it's very easy to see what each one is doing,
and what it's doing differently from the others.

We've only refactored the tests so far, let's check they still pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----


The next refactor is wanting to pass the selectors to `initialize()`.
Let's see what happens if we just _do that_ straight away, in the tests:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l024)
====
[source,diff]
----
@@ -40,14 +40,14 @@ describe("Superlists tests", () => {
   });

   it("error message should be hidden on input", () => {
-    initialize();
+    initialize(inputSelector, errorSelector);
     textInput.dispatchEvent(new InputEvent("input"));

     expect(errorMsg.checkVisibility()).toBe(false);
   });

   it("error message should not be hidden before input is fired", () => {
-    initialize();
+    initialize(inputSelector, errorSelector);
     expect(errorMsg.checkVisibility()).toBe(true);
   });
 });

----
====


Now we look at the tests:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----

They still pass!

You might have been expecting a failure to do with the fact that `initialize()`
was defined as taking no arguments, but we passed two?
But JavaScript is too chill for that.
You can call a function with too many or too few arguments,
and JS will just _deal with it_.

Let's fish those arguments out in `initialize()`:



[role="sourcecode"]
.src/lists/static/lists.js (ch16l025)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    const errorMsg = document.querySelector(errorSelector);
    errorMsg.style.display = "none";
  };
};
----
====


And the tests still pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s
----


Let's deliberately use the arguments the wrong way round,
just to check we get a failure:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l026)
====
[source,javascript]
----
const initialize = (errorSelector, inputSelector) => {
----
====

Phew, that does indeed fail:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:46:40
<Jasmine>
----

OK, back to the right way around:

[role="sourcecode"]
.src/lists/static/lists.js (ch16l027)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
----
====


=== Does it work?

And for the moment of truth, we'll pull in our script
and invoke our initialize function on our real pages.

Let's use another `<script>` tag to include our _lists.js_,
and strip down the the inline javascript to just calling `initialize()`
with the right selectors:


[role="sourcecode"]
.src/lists/templates/base.html (ch16l028)
====
[source,html]
----
    </div>

    <script src="/static/lists.js"></script>
    <script>
      initialize("#id_text", ".invalid-feedback");
    </script>

  </body>
</html>
----
====
// DAVID: Really we should be using the static tag here.
// https://docs.djangoproject.com/en/5.2/howto/static-files/

Aaaand we run our FT:

[subs="specialcharacters,quotes"]
----
$ *python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*
[...]

Ran 1 test in 3.023s

OK
----

Hooray!  That's a commit!
((("", startref="JSTkey16")))


[subs="specialcharacters,quotes"]
----
$ *git add src/lists*
$ *git commit -m"Despike our js, add jasmine tests"*
----


NOTE: We're using `<script>` tag to import our code,
  but modern JavaScript lets you use `import` and `export` to explicitly
  import particular parts of your code.
  But that involves specifying the scripts as modules,
  which is fiddly to get working with the single-file test runner we're using,
  so I decided to use the "simple" old fashioned way.
  By all means investigate modules in your own projects!


=== Testing Integration with CSS and Bootstrap

As the tests flashed past, you may have noticed an unsatisfactory bit of red,
still left around our input box.

Wait a minute!  We forgot one of the key things we learned in our spike!

[role="scratchpad"]
*****
* Remove `is-invalid` bootstrap css class to hide error message & red border
*****

We don't need to manually hack `style.display=none`,
we can work _with_ the Bootstrap framework,
and just remove the `.is-invalid` class.

OK let's try it in our implementation:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l029)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    textInput.classList.remove("is-invalid");
  };
};
----
====

Oh dear, it seems like that doesn't quite work:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:46:40
<Jasmine>
----

What's happening here?

Well, as hinted in the section title,
we're now relying on the integration with Bootstrap's CSS,
and our test runner doesn't know about Bootstrap yet.

We can include it in a reasonably familiar way,
which is by including it in the `<head>` of our _SpecRunner.html_ file:


[role="sourcecode"]
.src/lists/static/tests/SpecRunner.html (ch16l030)
====
[source,html]
----
  <link rel="stylesheet" href="lib/jasmine-4.6.1/jasmine.css">

  <!-- Bootstrap CSS -->
  <link href="../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <script src="lib/jasmine-4.6.1/jasmine.js"></script>
----
====


That gets us back to passing tests:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----


Let's do a little more refactoring.
If your editor is set up to do some JavaScript linting,
you might have seen a warning saying:


[role="skipme"]
----
'errorSelector' is declared but its value is never read.
----


Great!  Looks like we can get away with just one argument to our `initialize()` function:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l031)
====
[source,javascript]
----
const initialize = (inputSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    textInput.classList.remove("is-invalid");
  };
};
----
====

Are you enjoying the way the tests keep passing
even though we're giving the function too many arguments?
JavaScript is so chill, man.
Let's strip them down anyway:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l032)
====
[source,javascript]
----
@@ -40,14 +40,14 @@ describe("Superlists tests", () => {
   });

   it("error message should be hidden on input", () => {
-    initialize(inputSelector, errorSelector);
+    initialize(inputSelector);
     textInput.dispatchEvent(new InputEvent("input"));

     expect(errorMsg.checkVisibility()).toBe(false);
   });

   it("error message should not be hidden before input is fired", () => {
-    initialize(inputSelector, errorSelector);
+    initialize(inputSelector);
     expect(errorMsg.checkVisibility()).toBe(true);
   });
 });
----
====

And the base template, yay.
Nothing more satisfying than _deleting code_:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l033)
====
[source,html]
----
    <script>
      initialize("#id_text");
    </script>
----
====


And we can run the FT one more time, just for safety.


----
OK
----


// TODO: aside on testing tradeoffs:
// * Should we change the FT to assert on classes rather than visibility? prob not.
// * Should we change the unit tests to not need boostrap tho? maybe.



[[columbo-onload]]
=== Columbo Says: wait for Onload

[quote, Columbo (fictional trenchcoat-wearing American detective known for his persistence)]
______________________________________________________________
Wait, there's just one more thing...
______________________________________________________________

As always, there's one final thing.
Whenever you have some JavaScript that interacts with the DOM,
it's good to wrap it in some "onload" boilerplate
to make sure that the page has fully loaded before it tries to do anything.
Currently it works anyway,
because we've placed the `<script>` tag right at the bottom of the page,
but we shouldn't rely on that.

https://developer.mozilla.org/en-US/docs/Web/API/Window/load_event[Read more here]

The modern js onload boilerplate is minimal:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l034)
====
[source,javascript]
----
    <script>
      window.onload = () => {
        initialize("#id_text");
      };
    </script>
----
====

That's a commit folks!

[subs="specialcharacters,quotes"]
----
$ *git status*
$ *git add src/lists/static*  # all our js and tests
$ *git add src/lists/templates*  # changes to the base template
$ *git commit -m"Javascript to hide error messages on input"*
----


=== JavaScript Testing in the TDD Cycle


((("JavaScript testing", "in the TDD cycle", secondary-sortas="TDD cycle")))
((("Test-Driven Development (TDD)", "JavaScipt testing in")))
You may be wondering how these JavaScript tests fit in with our "double loop" TDD cycle,
<<double-loop-tdd-ch17>>.

[[double-loop-tdd-ch17]]
.Double-loop TDD reminder
image::images/double-loop-tdd-simpler.png["Diagram showing an inner loop of red/green/refactor, and an outer loop of red-(inner loop)-green."]

The answer is that the Javascript unit test/code cycle
plays exactly the same role as the Python unit one.

1. Write an FT and see it fail.
2. Figure out what kind of code you need next: Python or JavaScript?
3. Write a unit test in either language, and see it fail.
4. Write some code in either language, and make the test pass.
5. Rinse and repeat.


Phew. Well, hopefully some sense of closure there.
The next step is to deploy our new code to our servers.

There is more JavaScript fun in this book too!
Have a look at the <<appendix_rest_api>>
when you're ready for it.
((("", startref="FTjava16")))


NOTE: Want a little more practice with JS?
    See if you can get our error messages to be hidden
    when the user clicks inside the input element,
    as well as just when they type in it.
    You should be able to FT it too, if you want a bit of extra Selenium practice.


[role="less_space pagebreak-before"]
.JavaScript Testing Notes
*******************************************************************************

* ((("Selenium", "and JavaScript", secondary-sortas="JavaScript")))
  One of the great advantages of Selenium is that it allows you to test that
  your JavaScript really works, just as it tests your Python code.
  But, as always, FTs are a very blunt tool, so it's often worth pairing them
  with some lower-level tests.

* There are many JavaScript test running libraries out there.
  Jasmine has been around for a while,
  but the others are also worth investigating.
  ((("JavaScript testing", "test running libraries")))

* No matter which testing library you use,
  if you're working with "Vanilla' JavaScript (i.e., not a framework like React),
  you'll need to work around the key "gotchas" of JavaScript,
    - the DOM and HTML fixtures
    - global state
    - understanding and controlling execution order.
((("JavaScript testing", "managing global state")))
((("global state")))

* An awful lot of frontend work these days is done in frameworks,
  React being the 1,000-pound gorilla.
  There are lots of resources on React testing out there,
  so I'll let you go out and find them if you need them.

*******************************************************************************

//IDEA: take the opportunity to use {% static %} tag in templates?
