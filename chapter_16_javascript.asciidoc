[[chapter_16_javascript]]
== A Gentle Excursion Into JavaScript

[quote, Geoffrey Willans, English author and journalist]
______________________________________________________________
You can never understand one language until you understand at least two.
______________________________________________________________


.ðŸš§ Warning, Fresh rewrite
*******************************************************************************
This chapter is a very fresh rewrite for the third edition.

I've switched from QUnit to Jasmine for the JavaScript testing,
and updated all the listings to use modern ES6 JavaScript.

It's a first draft, so I'd love your feedback! obeythetestinggoat@gmail.com

*******************************************************************************

Our new validation logic is good,
but wouldn't it be nice if the duplicate item error messages disappeared
once the user started fixing the problem?
Just like our nice HTML5 validation errors do?
For that we'd need a teeny-tiny bit of JavaScript.


// RITA: In this paragraph, please tell us how we're going to play around with JavaScript and what it'll teach us. I mean, you're going to use Javascript to make it so the duplicate item error message disappears once the user fixes the problem.
Python is a delightful language to program in.
JavaScript wasn't always that.
But many of the rough edges have been smoothed off,
and I think it's fair to say that JavaScript is actually quite nice now.
And in the world of web development, using JavaScript is unavoidable.
So let's dip our toes in, and see if we can't have a bit of fun.

// RITA: Consider dropping mention of JavaScript: The Good Parts and just referencing your more recent recommendations. If you've read Eloquent JavaScript, consider dropping "I've heard good things" to make your recommendation sound more confident. I suppose you could still mention JavaScript: The Good Parts after that.
NOTE: I'm going to assume you know the basics of JavaScript syntax.
  If not, I used to recommend https://amzn.to/3UXVUKd[JavaScript: The Good Parts],
  which was the best guide, once upon a time.
  Nowadays many of the "bad parts" it warns against have actually been fixed,
  so it's a little out of date.
  I'd say it's still a good guide, but if you find it too anachronistic,
  I've heard good things about
  https://eloquentjavascript.net[Eloquent JavaScript].
  ((("JavaScript testing", "additional resources")))
// CSANAD: maybe we could also mention MDN
// https://developer.mozilla.org/en-US/docs/Web/JavaScript#for_complete_beginners


=== Starting with an FT

((("JavaScript testing", "functional test")))
((("functional tests (FTs)", "JavaScript", id="FTjava16")))

// RITA: In this first paragraph, please tell us WHY we're adding a new FT. How does this relate to making it so the duplicate item error messages disappear once the user fixes the problem? Give us context.
Let's add a new functional test to the `ItemValidationTest` class:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l001)
====
[source,python]
----
def test_error_messages_are_cleared_on_input(self):
    # Edith starts a list and causes a validation error:
    self.browser.get(self.live_server_url)
    self.get_item_input_box().send_keys("Banter too thick")
    self.get_item_input_box().send_keys(Keys.ENTER)
    self.wait_for_row_in_list_table("1: Banter too thick")
    self.get_item_input_box().send_keys("Banter too thick")
    self.get_item_input_box().send_keys(Keys.ENTER)
    self.wait_for(  # <1>
        lambda: self.assertTrue(  # <1>
            self.browser.find_element(
                By.CSS_SELECTOR, ".invalid-feedback"
            ).is_displayed()  # <2>
        )
    )

    # She starts typing in the input box to clear the error
    self.get_item_input_box().send_keys("a")

    # She is pleased to see that the error message disappears
    self.wait_for(
        lambda: self.assertFalse(
            self.browser.find_element(
                By.CSS_SELECTOR, ".invalid-feedback"
            ).is_displayed()  # <2>
        )
    )
----
====

<1> We use another of our `wait_for` invocations, this time with `assertTrue`.

<2> `is_displayed()` tells you whether an element is visible or not.
    We can't just rely on checking whether the element is _present_ in the DOM,
    because we're now going to mark elements as hidden,
    rather than removing them from the DOM altogether.


The functional test fails appropriately:



[role="small-code"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*]

FAIL: test_error_messages_are_cleared_on_input (functional_tests.test_list_item
_validation.ItemValidationTest.test_error_messages_are_cleared_on_input)
[...]
  File "...goat-book/src/functional_tests/test_list_item_validation.py", line
89, in <lambda>
    lambda: self.assertFalse(
            ^^^^^^^^^^^^^^^^^
AssertionError: True is not false
----

// RITA: Move on to do what?
But, before we move on:  three strikes and refactor!
We've got several places where we find the error element using CSS.
Let's move the logic to a helper function:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l002)
====
[source,python]
----
class ItemValidationTest(FunctionalTest):
    def get_error_element(self):
        return self.browser.find_element(By.CSS_SELECTOR, ".invalid-feedback")

    [...]
----
====

And we then make three replacements in 'test_list_item_validation', like this:

[role="sourcecode"]
.src/functional_tests/test_list_item_validation.py (ch16l003)
====
[source,python]
----
    self.wait_for(
        lambda: self.assertEqual(
            self.get_error_element().text,
            "You've already got this in your list",
        )
    )
[...]
    self.wait_for(
        lambda: self.assertTrue(self.get_error_element().is_displayed()),
    )
[...]
    self.wait_for(
        lambda: self.assertFalse(self.get_error_element().is_displayed()),
    )
----
====

We still have our expected failure:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python src/manage.py test functional_tests.test_list_item_validation*]
[...]
    lambda: self.assertFalse(self.get_error_element().is_displayed()),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: True is not false
----

And we can commit this as the first cut of our FT.


TIP: I like to keep helper methods in the FT class that's using them,
    and only promote them to the base class when they're actually needed elsewhere.
    It stops the base class from getting too cluttered. YAGNI.


[[js-spike]]
=== A Quick "Spike"

((("spike")))
((("exploratory coding", see="also spiking and de-spiking")))
((("spiking and de-spiking", "defined")))
((("prototyping", see="spiking and de-spiking")))
This will be our first bit of JavaScript.
We're also interacting with the Bootstrap CSS framework,
which we maybe don't know very well.

In <<chapter_14_simple_form>> we saw that you
can use a unit test as a way of exploring a new API or tool.
Sometimes though, you just want to hack something together
without any tests at all, just to see if it works,
to learn it or get a feel for it.

That's absolutely fine.
When learning a new tool or exploring a new possible solution,
it's often appropriate to leave the rigorous TDD process to one side,
and build a little prototype without tests, or perhaps with very few tests.
The goat doesn't mind looking the other way for a bit.

// SEBASTIAN: That's a very important comment about leaving TDD when we need to experiment.
//      Kudos for placing it here!

This kind of prototyping activity is often called a "spike",
for http://stackoverflow.com/questions/249969/why-are-tdd-spikes-called-spikes[
reasons that aren't entirely clear],
but it's a nice memorable name.footnote:[
This chapter shows a very small spike.
We'll come back and look at the spiking process again,
with a weightier Python/Django example,
in <<chapter_18_spiking_custom_auth>> .]
// CSANAD: I tried placing this closing ] correctly so that it does not show up
// in the text: "memorable name.[1] .]" but no success.

TIP: Always do a commit before embarking on a Spike.


==== A Simple Inline Script

// RITA: First thing you came up with to do what?
I hacked around for a bit,
and here's more or less the first thing I came up with.
I'm adding the code inline, in a `<script>` tag
at the bottom of our _base.html_ template:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l004)
====
[source,html]
----
    </div>

    <script>
      const textInput = document.querySelector("#id_text");  //<1>
      textInput.oninput = () => {  //<2><3>
        const errorMsg = document.querySelector(".invalid-feedback");
        errorMsg.style.display = "none";  //<4>
      }
    </script>
----
====

<1> `document.querySelector` is a way of finding an element in the DOM,
    using CSS selector syntax, very much like the Selenium
    `find_element(By.CSS_SELECTOR)` method from our FTs.
    Grizzled readers may remember having to use jQuery's `$` function for this.

<2> `oninput` is how you attach an event listener "callback" function,
    which will be called whenever the user inputs something into the text box.

<3> Arrow functions `() => {...}` are the new way of writing anonymous functions
    in JavaScript, a bit like Python's `lambda` syntax.
    I think they're cute!
    Arguments go in the round brackets,
    the function body goes in the curly braces.
    So this is a function that takes no arguments,
    or I should say, ignores any arguments you try to give it.
    What does it do?

<4> It finds the error message element,
    and then hides it by setting its `style.display` to "none".

That's actually good enough to get our FT passing:

[subs="specialcharacters,quotes"]
----
$ *python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*
Found 1 test(s).
[...]
.
 ---------------------------------------------------------------------
Ran 1 test in 3.284s

OK
----


TIP: It's good practice to put your script loads at the end of your body HTML,
    as it means the user doesn't have to wait for all your JavaScript to load
    before they can see something on the page.
    It also helps to make sure most of the DOM has loaded before any scripts run.
    See also the <<columbo-onload>> section, later in this chapter.


==== Using the Browser Devtools

The test might be happy, but our solution is a little unsatisfactory.
If you actually try it in your browser,
you'll see that although the error message is gone,
the input is still red and invalid-looking, see <<input-still-red>>.

[[input-still-red]]
.The error message is gone but the input box is still red
image::images/error-gone-but-input-still-red.png["Screenshot of our page where the error div is gone but the input is still red."]

You're probably imagining that this has something to do with Bootstrap.
We might have been able to hide the error message,
but we also need to tell bootstrap that this input no longer has invalid contents.

This is where I'd normally open up the browser
https://firefox-source-docs.mozilla.org/devtools-user/[devtools].
If level 1 of hacking is spiking code directly into an inline `<script>` tag,
level 2 is hacking things directly in the browser,
where it's not even saved to a file!

[[editing-html-in-devtools]]
.Editing the HTML in the Browser Devtools
image::images/editing-html-via-devtools.png["Screenshot of the browser devtools with us editing the classes for the input element"]

In <<editing-html-in-devtools>> you can see me directly editing the HTML of the page,
and finding out that removing the `is-invalid` class from the input element
seems to do the trick.
It not only removes the error message,
but also the red border around the input box.

We have a reasonable solution now, time to de-spike!


.Do We Really Need to Write Unit Tests for This?
*******************************************************************************

// RITA: The first sentence following a heading should not refer syntactically to the heading; words should be repeated where necessary.
By this point in the book, you probably know I'm going to say "yes",
but let's talk about it anyway.

// RITA: What functionality?
Our FT definitely covers this functionality,
and we could extend it if we wanted to,
to check on the colour of the input box,
or to look at the input element's CSS classes.

And if I was really sure that this was the only bit of JavaScript
we were ever going to write,
I probably would be tempted to leave it at that.

But I want to press on for two reasons.
Firstly, because any book on web development has to talk about JavaScript,
and in a TDD book, I have to show a bit of TDD in JavaScript.

More importantly though, as always we have the boiled frog problem.
We might not have enough JavaScript _yet_ to justify a full test suite,
but what about when we come along later and add a tiny bit more?
And a tiny bit more again?

It's always a judgement call, and on the one hand YAGNI,
but on the other hand, I think it's best to put the scaffolding in place early,
so that going test-first is the easy choice later.

I can already think of several extra things I'd want to do in the frontend!
What about re-setting the input to being invalid if someone types in the
exact duplicate text again?

*******************************************************************************


=== Setting Up a Basic JavaScript Test Runner


((("test running libraries")))
((("JavaScript testing", "test running libraries", id="JStestrunner16")))
((("pytest")))
Choosing your testing tools in the Python world is fairly straightforward.
The standard library `unittest` package is perfectly adequate,
and the Django test runner also makes a good default choice.
More and more though, people will choose http://pytest.org/[pytest]
for its `assert` based assertions, and its fixture management.
We don't need to get into the pros and cons now!
The point is that there's a "good enough" default,
and there's one main popular alternative.

The JavaScript world has more of a proliferation!
Mocha, Karma, Jester, Chai, Ava, and Tape are just a few of the options
I came across when researching the Third Edition.

I chose Jasmine, because it's still popular despite being around for nearly a decade,
and because it offers a "standalone" test runner that you can use
without needing to dive into the whole Node/NPM ecosystem.
((("Jasmine")))


// TODO: go all in and use jasmine-browser-runner instead,
// it will let me use ES6 modules.

Let's download Jasmine now:

[role="small-code"]
[subs="specialcharacters,quotes"]
----
$ *wget -O jasmine.zip \
  https://github.com/jasmine/jasmine/releases/download/v4.6.1/jasmine-standalone-4.6.1.zip*
$ *unzip jasmine.zip -d src/lists/static/tests*
$ *rm jasmine.zip*
# if you're on Windows you may not have wget or unzip,
# but i'm sure you can manage to manually download and unzip the jasmine release

# move the example tests "Spec" file to a more central location
$ *mv src/lists/static/tests/spec/PlayerSpec.js src/lists/static/tests/Spec.js*

# delete all the other stuff we don't need
$ *rm -rf src/lists/static/tests/src*
$ *rm -rf src/lists/static/tests/spec*
----
//005-1

That leaves us with a directory structure like this:

[subs="specialcharacters,quotes"]
----
$ *tree src/lists/static/tests*
src/lists/static/tests
â”œâ”€â”€ MIT.LICENSE
â”œâ”€â”€ Spec.js
â”œâ”€â”€ SpecRunner.html
â””â”€â”€ lib
    â””â”€â”€ jasmine-4.6.1
        â”œâ”€â”€ boot0.js
        â”œâ”€â”€ boot1.js
        â”œâ”€â”€ jasmine-html.js
        â”œâ”€â”€ jasmine.css
        â”œâ”€â”€ jasmine.js
        â””â”€â”€ jasmine_favicon.png

3 directories, 9 files
----

We need to go edit the _SpecRunner.html_ file
to take into account the things we've moved around:


[role="sourcecode"]
.src/lists/static/tests/SpecRunner.html (ch16l006)
[source,diff]
----
@@ -14,12 +14,10 @@
   <script src="lib/jasmine-4.6.1/boot1.js"></script>

   <!-- include source files here... -->
-  <script src="src/Player.js"></script>
-  <script src="src/Song.js"></script>
+  <script src="../lists.js"></script>

   <!-- include spec files here... -->
-  <script src="spec/SpecHelper.js"></script>
-  <script src="spec/PlayerSpec.js"></script>
+  <script src="Spec.js"></script>

 </head>
----

We change the "source files" to point at a (for-now imaginary)
_lists.js_ file that we'll put into the _static_ folder,
and we change the "spec files" to point at the single _Spec.js_ file,
in the _static/tests_ folder.

Now let's open up the _Spec.js_ file,
and strip it down to a single minimal smoke test:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l007)
====
[source,javascript]
----
describe("Superlists tests", () => {  //<1>

  it("smoke test", () => {  //<2>
    expect(1 + 1).toEqual(2);  //<3>
  });

});
----
====


<1> The `describe` block is a way of grouping tests together,
    a bit like we use classes in our Python tests.
    It starts with a name, and then an arrow function for its body.

<2> The `it` block is a single test, a bit like a method in a Python test class.
    Similarly to the `describe` block, we have a name and then a function
    to contain the test code.

<3> Now we have our assertion.
    This is a little different from assertions in unittest;
    it's using what's sometimes called "expect" style,
    often also seen in the Ruby world.
    We wrap our "actual" value in the `expect()` function,
    and then our assertions are methods on the resulting expect object,
    where `.toEqual` is the equivalent of `assertEqual` in Python.


Let's see how that looks in our browser (<<jasmine-specrunner-green>>):
// CSANAD: I would add an instruction something like "simply open the file
// `SpecRunner.html` in your browser".

[[jasmine-specrunner-green]]
.The Jasmine Spec runner in action
image::images/jasmine-in-browser-green.png["Jasmine browser-based spec runner showing one passing test."]


Let's try adding a deliberate failure to see what that looks like:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l008)
====
[source,javascript]
----
  it("smoke test", () => {
    expect(1 + 1).toEqual(3);
  });
----
====

Now if we refresh our browser, we'll see red (<<jasmine-specrunner-red>>):

[[jasmine-specrunner-red]]
.Our Jasmine tests are now red
image::images/jasmine-in-browser-red.png["Jasmine browser-based spec runner showing one failing test, with lots of red."]


.Is the Jasmine Standalone Browser Test Runner Unconventional?
*******************************************************************************

// RITA: Again, the first sentence following a heading should not refer syntactically to the heading; words should be repeated where necessary.
I think it probably is, to be honest.
Although the JavaScript world moves so fast,
I could be wrong by the time you read this.

What I do know is that, along with moving very fast,
JavaScript things can very quickly become very complicated.
A lot of people are working with frameworks these days (React is the main one),
and along with that comes TypeScript, transpilers, to say nothing of Node.js,
`npm`, the `node_modules` folder, and a very steep learning curve.

In this chapter my aim is to stick with the basics.
The standalone / browser-based test runner lets us write tests without
needing to install node or anything else,
and it lets us tests interactions with the DOM.

That's enough to give us a basic environment in which to do TDD in JavaScript.

If you decide to go further in the world of frontend,
you probably will eventually get into the complexity of frameworks
and TypeScript and transpilers,
but the basics we work with here will still be a good foundation.

If you want to take a small step further,
look into installing the `jasmine-browser-runner` npm package,
and a bit of fiddling with its config file should let you run our tests
from the command-line instead of with a browser.
*******************************************************************************


((("", startref="JStestrunner16")))
((("", startref="qunit16")))

=== Testing with some DOM content

What do we want to test?
We want some JavaScript that will hide the `.invalid-feedback` error div,
when the user starts typing into the input box.

In other words, our code is going to interact with the `input` element
on the page, and the `div.invalid-feedback`.

Let's see how to set up some copies of these elements in our JS test environment,
for our tests and our code to interact with.


[role="sourcecode dofirstch16l009"]
.src/lists/static/tests/Spec.js (ch16l010)
====
[source,javascript]
----
describe("Superlists tests", () => {
  let testDiv;  //<3>

  beforeEach(() => {  //<1>
    testDiv = document.createElement("div");
    testDiv.innerHTML = `  //<2>
      <form>
        <input
          id="id_text"
          name="text"
          class="form-control form-control-lg is-invalid"
          placeholder="Enter a to-do item"
          value="Value as submitted"
          aria-describedby="id_text_feedback"
          required
        />
        <div id="id_text_feedback" class="invalid-feedback">An error message</div>
      </form>
    `
    document.body.appendChild(testDiv)
  });

  afterEach(() => {  //<1>
    testDiv.remove();
  });
  [...]
----
====

<1> The `beforeEach` and `afterEach` functions are Jasmine's equivalent of `setUp` and `tearDown`.

<2> We create a new div element, and populate it with some HTML that matches
  the elements we care about from our Django template.
  Notice the use of backticks (+`+) to allow us to write multi-line strings.
  Depending on your text editor, it may even nicely syntax-highlight the HTML for you.

<3> A little quirk of JavaScript here,
  because we want the same `testDiv` variable to be available inside both the
  `beforeEach` and `afterEach` functions, we declare the variable with this `let`
  in the containing scope outside of both of them.

In theory, we could just add the HTML to the `SpecRunner.html` file,
but by using `beforeEach` and `afterEach`,
I'm making sure that each test gets a completely fresh copy of the html elements involved,
so that one test can't affect another.


Let's now have a play with our testing framework,
to see if we can find DOM elements and make assertions on whether they are visible.
We'll also try the same `style.display=none` hiding technique
that we originally used in our spiked code.


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l011)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);  //<1>
  });

  it("check we know how to hide things", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";  //<2>
    expect(errorMsg.checkVisibility()).toBe(false);  //<3>
  });
----
====
// CSANAD: I personally like phrasing test messages in singular 3rd person
// because then it reads more natural:
// "it checks whether foo does bar" so I suggest
// "sense-checks our html fixture".
// Also, I would refine the second test's message, maybe:
// "checks if we know how to hide things" or
// "checks if display set to none hides the element"
//
// Same chain of thought: I also prefer the `describe()` description to
// flow into the it() -s:
// ```
// describe("Superlists", () => {
//   it("should foo when bar");
//   it("should not baz if qux")
// })
// ```
// reads as nice sentences in the test output:
// Superlists > should foo when bar
// Superlists > should not baz if qux

<1> We retrieve our error div with `querySelector` again,
    and then use another fairly new API in JavaScript-Land called `checkVisibility()`.

// SEBASTIAN: Might use some short explanation what checkVisibility is and what it does,
//      at least from a perspective of a novice programmer reading this book

<2> We manually hide the element in the test,
  by setting its `style.display` to "none".
// CSANAD: this step feels like implementation in the test.
// I would add some explanation for what this is about:
// "we add another sort-of smoke test to check if this would be a sufficient
// way for our tests in the future to pass."


<3> And we check it worked, with `checkVisibility()` again.


Notice that I'm being really good about splitting things out into multiple tests,
with one assertion each.
Jasmine encourages that, for example, by deprecating the ability to pass
on-failure messages into individual `expect/toBe` expressions.


If you refresh the browser, you should see that all passes:

// RITA: You don't usually have captions other than commits. Was this one intentional?
[[first-jasmine-output]]
.Expected results from Jasmine in the browser
====
[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * check we know how to hide things
  * sense-check our html fixture
----
====

// RITA: Should this be put into a note box?
(I'll show the Jasmine outputs as text, as in <<first-jasmine-output>>, from now on,
to avoid filling the chapter with screenshots.)



=== Building a JavaScript Unit Test for Our Desired Functionality


((("JavaScript testing", "unit test")))
((("unit tests", "JavaScript")))
Now that we're acquainted with our JavaScript testing tools,
we can switch back to just one test and start to write the real thing:

[role="sourcecode small-code"]
.src/lists/static/tests/Spec.js (ch16l012)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {  //<1>
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {  //<2>
    const textInput = document.querySelector("#id_text");  //<3>
    const errorMsg = document.querySelector(".invalid-feedback");

    textInput.dispatchEvent(new InputEvent("input"));  //<4>

    expect(errorMsg.checkVisibility()).toBe(false);  //<5>
  });
----
====

<1> Let's keep the first smoke test, it's not doing any harm.

<2> Let's change the second one, and give it a name that describes
  what we want to happen;
  our objective is that, when the user starts typing into the input box,
  we should hide the error message.
// CSANAD: just like above, I would phrase it in 3rd person singular:
// it("hides the error message element on input", or
// it("checks if the error message is hidden on input", or something like this.

<3> We retrieve the `<input>` element from the DOM,
  in a similar way to how we found the error message div.

<4> Here's how we simulate a user typing into the input box.

<5> And here's our real assertion: the error div should be hidden after
  the input box sees an input event.


That gives us our expected failure:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:38:40
<Jasmine>
----


Now let's try re-introducing the code we hacked together in our spike,
into _lists.js_:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l014)
====
[source,javascript]
----
const textInput = document.querySelector("#id_text");
textInput.oninput = () => {
  const errorMsg = document.querySelector(".invalid-feedback");
  errorMsg.style.display = "none";
}
----
====


That doesn't work!  We get an _unexpected error_:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 2 failures, randomized with seed 12345      finished in 0.005s
Error during loading: TypeError: textInput is null in
file:///...goat-book/src/lists/static/lists.js line 2
Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:38:40
<Jasmine>
----
// CSANAD: this gives me `2 specs, 2 failures`
// Error during loading: Script error. in .../superlists/src/lists/static/lists.js line 0
//
// Although in the devtools console I do see that the error occurs on line 2,
// and textInput is null, but not on the SpecRunner UI.
// In fact, it's also the Script error on the next screenshot, and apart from
// console.logs, we will have not changed the code by then.
// If someone else confirms the error message is Script error, then we should
// change this a little, directing the readers to open the devtools console
// and see what's wrong: `Uncaught TypeError: textInput is null`.

`textInput is null` it says.   Let's see if we can figure out why.


=== Fixtures, Execution Order, and Global State: Key Challenges of JS Testing



((("JavaScript testing", "managing global state")))
((("global state")))
((("JavaScript testing", "key challenges of", id="JSTkey16")))
((("HTML fixtures")))

// RITA: In this paragraph, please tell us how this relates to the goal of the example in this chapter. How does this help the goal of this chapter, which is to get rid of the duplicate item error messages as they are resolved?
One of the difficulties with JavaScript in general, and testing in particular,
is in understanding the order of execution of our code (i.e., what happens when).
When does our code in _lists.js_ run, and when does each of our tests run?  And
how does that interact with global state, that is, the DOM of our web page,
and the fixtures that we've already seen are supposed to be cleaned up after each test?


==== console.log for Debug Printing

((("console.log")))
Let's add a couple of debug prints, or "console.logs":

[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l015)
====
[source,javascript]
----
console.log("Spec.js loading");

describe("Superlists tests", () => {
  let testDiv;

  beforeEach(() => {
    console.log("beforeEach");
    testDiv = document.createElement("div");

    [...]

  it("sense-check our html fixture", () => {
    console.log("in test 1");
    const errorMsg = document.querySelector(".invalid-feedback");
    [...]

  it("error message should be hidden on input", () => {
    console.log("in test 2");
    const textInput = document.querySelector("#id_text");
    [...]
----
====

And the same in our actual JS code:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l016)
====
[source,javascript]
----
console.log("lists.js loading");
const textInput = document.querySelector("#id_text");
textInput.oninput = () => {
  const errorMsg = document.querySelector(".invalid-feedback");
  errorMsg.style.display = "none";
};
----
====


Rerun the tests, opening up the browser debug console (Ctrl-Shift-I or Cmd-Alt-I)
and you should see something like <<jasmine-with-js-console>>.

[[jasmine-with-js-console]]
.Jasmine tests with console.log debug outputs
image::images/jasmine-console-logs.png["Jasmine tests with console.log debug outputs"]

What do we see?

* _lists.js_ loads first
* then we see the error saying `textInput is null`
* then we see our tests loading in Spec.js
* then we see a `beforeEach`, which is when our test fixture actually gets added to the DOM
* then we see the first test run.

This explains the problem - when _lists.js_ loads,
the input node doesn't exist yet.



=== Using an Initialize Function for More Control Over Execution Time

We need more control over the order of execution of our JavaScript.
Rather than just relying on the code in _lists.js_ running
whenever it is loaded by a `<script>` tag,
we can use a common pattern, which is to define an "initialize" function,
and call that when we want to in our tests (and later in real life):


[role="sourcecode"]
.src/lists/static/lists.js (ch16l017)
====
[source,javascript]
----
console.log("lists.js loading");
const initialize = () => {
  console.log("initialize called");
  const textInput = document.querySelector("#id_text");
  textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  };
};
----
====


And in our tests file, we call `initialize()` in our key test:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l018)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    console.log("in test 1");
    const errorMsg = document.querySelector(".invalid-feedback");
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {
    console.log("in test 2");
    const textInput = document.querySelector("#id_text");
    const errorMsg = document.querySelector(".invalid-feedback");

    initialize();  //<1>
    textInput.dispatchEvent(new InputEvent("input"));

    expect(errorMsg.checkVisibility()).toBe(false);
  });
});
----
====
//RITA: What does "here" refer to?
<1> Here.  We don't need to call it in our sense-check.


And that will actually get our tests passing!


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
----
// RITA: Why does it make more sense now?
And now the `console.log` outputs should make more sense:

[role="skipme"]
----
lists.js loading    lists.js:1:9
Spec.js loading     Spec.js:1:9
beforeEach          Spec.js:7:13
in test 2           Spec.js:37:13
initialize called   lists.js:3:11
[...]
----
// CSANAD: maybe unimportant, but we didn't display
// beforeEach          Spec.js:7:13
// in test 1           Spec.js:31:13

=== Deliberately Breaking Our Code to Force Ourselves To Write More Tests

I'm always nervous when I see green tests.
We've copy-pasted five lines of code from our spike with just one test.
That was a little too easy, even despite that little `initialize()` dance.

// RITA: Why do we want to try to deliberately break the initialize function? Give us context.
Let's change our `initialize()` function to deliberately break it.
What if we just immediately hide errors?

[role="sourcecode"]
.src/lists/static/lists.js (ch16l019)
====
[source,javascript]
----
const initialize = () => {
  // const textInput = document.querySelector("#id_text");
  // textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  // };
};
----
====


Oh dear, sure enough the tests just pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
2 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
----


We need an extra test, to check that our `initialize()` function
isn't overzealous:



[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l020)
====
[source,javascript]
----
  it("error message should be hidden on input", () => {
    [...]
  });

  it("error message should not be hidden before input is fired", () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    initialize();
    expect(errorMsg.checkVisibility()).toBe(true);  //<1>
  });
----
====
// CSANAD: suggestion for test message:
// `it("should not hide the error message before providing input",...`

<1> In this test we don't fire the input event with `dispatchEvent`,
  so we expect the error message to still be visible.


That gives us our expected failure:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should not be hidden before input is fired
Expected false to be true.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:48:40
<Jasmine>
----


Which justifies us to restore the `textInput.oninput()`:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l021)
====
[source,javascript]
----

const initialize = () => {
  const textInput = document.querySelector("#id_text");
  textInput.oninput = () => {
    const errorMsg = document.querySelector(".invalid-feedback");
    errorMsg.style.display = "none";
  };
};
----
====


=== Red, Green, Refactor: Removing Hardcoded Selectors

The `#id_text` and `.invalid-feedback` selectors are "magic constants" at the moment.
It would be better to pass them in, both in the tests and in _base.html_,
so that they're defined in the same file that actually has the HTML elements.

And while we're at it, our tests could do with a bit of refactoring too!

// RITA: Please tell us the goal of the following code block.

[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l022)
====
[source,javascript]
----
describe("Superlists tests", () => {
  const inputId = "id_text";  //<1>
  const errorClass = "invalid-feedback";  //<1>
  const inputSelector = `#${inputId}`  //<2>
  const errorSelector = `.${errorClass}`;  //<2>
  let testDiv;
  let textInput;  //<3>
  let errorMsg;  //<3>

  beforeEach(() => {
    console.log("beforeEach");
    testDiv = document.createElement("div");
    testDiv.innerHTML = `
      <form>
        <input
          id="${inputId}"  //<4>
          name="text"
          class="form-control form-control-lg is-invalid"
          placeholder="Enter a to-do item"
          value="Value as submitted"
          aria-describedby="id_text_feedback"
          required
        />
        <div id="id_text_feedback" class="${errorClass}">An error message</div>  //<4>
      </form>
    `
    document.body.appendChild(testDiv)
    textInput = document.querySelector(inputSelector);  //<5>
    errorMsg = document.querySelector(errorSelector);  //<5>
  });
----
====
// CSANAD: a semicolon is missing at the end of the line:
// const inputSelector = `#${inputId}`  //<2>
//
// I revoked the change so that we don't need to feed-thru this small change in
// the book-example repo and left it here as a TODO.

<1> Let's define some constants to represent the selectors for our input element
    and our error message div.

<2> We can use JavaScript's string interpolation (the equivalent of f-strings)
    to then define the css selectors for the same elements.

<3> We'll also set up some variables to hold the elements we're always referring
    to in our tests (these can't be constants, as we'll see shortly).

<4> We use a bit more interpolation to reuse the constants in our HTML template.
    A first bit of deduplication!

<5> Here's why `textInput` and `errorMsg` can't be constants:
    we're re-creating the DOM fixture in every `beforeEach`,
    so we need to re-fetch the elements each time.


Now we can apply some DRY to strip down our tests:



[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l023)
====
[source,javascript]
----
  it("sense-check our html fixture", () => {
    expect(errorMsg.checkVisibility()).toBe(true);
  });

  it("error message should be hidden on input", () => {
    initialize();
    textInput.dispatchEvent(new InputEvent("input"));

    expect(errorMsg.checkVisibility()).toBe(false);
  });

  it("error message should not be hidden before input is fired", () => {
    initialize();
    expect(errorMsg.checkVisibility()).toBe(true);
  });
----
====

You can definitely overdo DRY in test,
but I think this is working out very nicely.
Each test is between one and three lines long,
meaning it's very easy to see what each one is doing,
and what it's doing differently from the others.

We've only refactored the tests so far, let's check they still pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----


OK let's see what happens when we pass the selectors in to our initialize function:
// CSANAD: I think a sentence explaining why we try passing the selectors to
// `initialize()` would be helpful here.


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l024)
====
[source,diff]
----
@@ -40,14 +40,14 @@ describe("Superlists tests", () => {
   });

   it("error message should be hidden on input", () => {
-    initialize();
+    initialize(inputSelector, errorSelector);
     textInput.dispatchEvent(new InputEvent("input"));

     expect(errorMsg.checkVisibility()).toBe(false);
   });

   it("error message should not be hidden before input is fired", () => {
-    initialize();
+    initialize(inputSelector, errorSelector);
     expect(errorMsg.checkVisibility()).toBe(true);
   });
 });

----
====


Now we look at the tests:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----

They still pass!

You might have been expecting a failure to do with the fact that `initialize()`
was defined as taking no arguments, but we passed two?
But JavaScript is too chill for that.
You can call a function with too many or too few arguments,
and JS will just _deal with it_.

Let's fish those arguments out in `initialize()`:



[role="sourcecode"]
.src/lists/static/lists.js (ch16l025)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    const errorMsg = document.querySelector(errorSelector);
    errorMsg.style.display = "none";
  };
};
----
====


And the tests still pass:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s
----


Let's deliberately use the arguments the wrong way round,
just to check we get a failure:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l026)
====
[source,javascript]
----
const initialize = (errorSelector, inputSelector) => {
----
====

Phew, that does indeed fail:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:46:40
<Jasmine>
----

OK, back to the right way around:

[role="sourcecode"]
.src/lists/static/lists.js (ch16l027)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
----
====


=== Does it work?

And for the moment of truth, we'll pull in our script
and invoke our initialize function on our real pages.

Let's use another `<script>` tag to include our _lists.js_,
and strip down the the inline javascript to just calling `initialize()`
with the right selectors:


[role="sourcecode"]
.src/lists/templates/base.html (ch16l028)
====
[source,html]
----
    </div>

    <script src="/static/lists.js"></script>
    <script>
      initialize("#id_text", ".invalid-feedback");
    </script>

  </body>
</html>
----
====


Aaaand we run our FT:

[subs="specialcharacters,quotes"]
----
$ *python src/manage.py test functional_tests.test_list_item_validation.\
ItemValidationTest.test_error_messages_are_cleared_on_input*
[...]

Ran 1 test in 3.023s

OK
----

Hooray!  That's a commit!
((("", startref="JSTkey16")))


[subs="specialcharacters,quotes"]
----
$ *git add src/lists*
$ *git commit -m"Despike our js, add jasmine tests"*
----


NOTE: We're using `<script>` tag to import our code,
  but modern JavaScript lets you use `import` and `export` to explicitly
  import particular parts of your code.
  But that involves specifying the scripts as modules,
  which is fiddly to get working with the single-file test runner we're using,
  so I decided to use the "simple" old fashioned way.
  By all means investigate modules in your own projects!


=== Testing Integration with CSS and Bootstrap

As the tests flashed past, you may have noticed an unsatisfactory bit of red,
still left around our input box.

// RITA: Please make sure to conclude this in the spike section so that you can call back to it here.
Wait a minute!  We forgot one of the key things we learned in our spike!
We don't need to manually hack `style.display=none`,
we can work _with_ the Boostrap framework,
and just remove the `.is-invalid` class.

OK let's try it in our implementation:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l029)
====
[source,javascript]
----
const initialize = (inputSelector, errorSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    textInput.classList.remove("is-invalid");
  };
};
----
====


Oh dear, it seems like that doesn't quite work:

[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 1 failure, randomized with seed 12345      finished in 0.005s

Spec List | Failures

Superlists tests > error message should be hidden on input
Expected true to be false.
<Jasmine>
@file:///...goat-book/src/lists/static/tests/Spec.js:46:40
<Jasmine>
----

What's happening here?

Well, as hinted in the section title, we're now relying on the integration with Bootstrap's CSS,
and our test runner doesn't know about Bootstrap yet.

We can include it in a reasonably familiar way,
which is by including it in the `<head>` of our _SpecRunner.html_ file:



[role="sourcecode"]
.src/lists/static/tests/SpecRunner.html (ch16l030)
====
[source,html]
----
  <link rel="stylesheet" href="lib/jasmine-4.6.1/jasmine.css">

  <!-- Bootstrap CSS -->
  <link href="../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <script src="lib/jasmine-4.6.1/jasmine.js"></script>
----
====


That gets us back to passing tests:


[role="jasmine-output"]
[subs="specialcharacters,quotes"]
----
3 specs, 0 failures, randomized with seed 12345      finished in 0.005s


Superlists tests
  * error message should be hidden on input
  * sense-check our html fixture
  * error message should not be hidden before input is fired
----


Let's do a little more refactoring.
If your editor is set up to do some JavaScript linting,
you might have seen a warning saying:


[role="skipme"]
----
'errorSelector' is declared but its value is never read.
----


Great!  Looks like we can get away with just one argument to our `initialize()` function:


[role="sourcecode"]
.src/lists/static/lists.js (ch16l031)
====
[source,javascript]
----
const initialize = (inputSelector) => {
  const textInput = document.querySelector(inputSelector);
  textInput.oninput = () => {
    textInput.classList.remove("is-invalid");
  };
};
----
====

Enjoy the way the tests keep passing even though we're giving the function too many arguments!
Let's strip them down anyway:


[role="sourcecode"]
.src/lists/static/tests/Spec.js (ch16l032)
====
[source,javascript]
----
@@ -40,14 +40,14 @@ describe("Superlists tests", () => {
   });

   it("error message should be hidden on input", () => {
-    initialize(inputSelector, errorSelector);
+    initialize(inputSelector);
     textInput.dispatchEvent(new InputEvent("input"));

     expect(errorMsg.checkVisibility()).toBe(false);
   });

   it("error message should not be hidden before input is fired", () => {
-    initialize(inputSelector, errorSelector);
+    initialize(inputSelector);
     expect(errorMsg.checkVisibility()).toBe(true);
   });
 });
----
====

And the base template, yay.  Nothing more satisfying than _deleting code_:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l033)
====
[source,html]
----
    <script>
      initialize("#id_text");
    </script>
----
====

// RITA: Are we missing code here?
And we can run the FT one more time, just for safety.


// TODO: aside on testing tradeoffs:
// * Should we change the FT to assert on classes rather than visibility? prob not.
// * Should we change the unit tests to not need boostrap tho? maybe.




[[columbo-onload]]
=== Columbo Says: wait for Onload
// RITA: We need a descriptor to give Columbo context. 
[quote, Columbo, fictional American detective]
______________________________________________________________
Wait, there's just one more thing...
______________________________________________________________

// RITA: It might be nice to add something to the effect of "before we continue, it's good to do one more thing" so that it ties in with the Columbo quote.
Finally, whenever you have some JavaScript that interacts with the DOM,
it's always good to wrap it in some "onload" boilerplate
to make sure that the page has fully loaded before it tries to do anything.
Currently it works anyway,
because we've placed the `<script>` tag right at the bottom of the page,
but we shouldn't rely on that.

https://developer.mozilla.org/en-US/docs/Web/API/Window/load_event[Read more here]
// CSANAD: I think the link is better placed right after we mention the load
// event.

The modern js onload boilerplate is minimal:

[role="sourcecode"]
.src/lists/templates/base.html (ch16l034)
====
[source,javascript]
----
    <script>
      window.onload = () => {
        initialize("#id_text");
      };
    </script>
----
====



=== JavaScript Testing in the TDD Cycle


((("JavaScript testing", "in the TDD cycle", secondary-sortas="TDD cycle")))
((("Test-Driven Development (TDD)", "JavaScipt testing in")))
You may be wondering how these JavaScript tests fit in with our "double loop" TDD cycle.
The answer is that they play exactly the same role as our Python unit tests.

// RITA: Please add a sentence to introduce this list. What is the process described by the items in the list?
1. Write an FT and see it fail.
2. Figure out what kind of code you need next: Python or JavaScript?
3. Write a unit test in either language, and see it fail.
4. Write some code in either language, and make the test pass.
5. Rinse and repeat.

// RITA: Tell the reader what will happen in Part 3. Also, tell us the next step will be covered in the next chapter.
We're almost ready to move on to <<part3>>.  The last step is to deploy our
new code to our servers.
Don't forget to do a final commit including _base.html_ first!


There is more JavaScript fun in this book too!
Have a look at the <<appendix_rest_api,Rest API appendix>>
when you're ready for it.
((("", startref="FTjava16")))


NOTE: Want a little more practice with JavaScript?  See if you can get our
    error messages to be hidden when the user clicks inside the input element,
    as well as just when they type in it.  You should be able to FT it too.


[role="less_space pagebreak-before"]
.JavaScript Testing Notes
*******************************************************************************

* ((("Selenium", "and JavaScript", secondary-sortas="JavaScript")))
  One of the great advantages of Selenium is that it allows you to test that
  your JavaScript really works, just as it tests your Python code.
  But, as always, FTs are a very blunt tool, so it's often worth pairing them
  with some lower-level tests.

* There are many JavaScript test running libraries out there.
  Jasmine has been around for a while,
  but the others are also worth investigating.
  ((("JavaScript testing", "test running libraries")))

* No matter which testing library you use,
  if you're working with "Vanilla' JavaScript (i.e., not a framework like React),
  you'll need to work around the key "gotchas" of JavaScript,
    - the DOM and HTML fixtures
    - global state
    - understanding and controlling execution order.
((("JavaScript testing", "managing global state")))
((("global state")))

* An awful lot of frontend work these days is done in frameworks,
  React being the 1,000-pound gorilla.
  There are lots of resources on React testing out there,
  so I'll let you go out and find them if you need them.

*******************************************************************************

//IDEA: take the opportunity to use {% static %} tag in templates?
